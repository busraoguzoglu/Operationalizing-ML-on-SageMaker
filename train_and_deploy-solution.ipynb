{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>C4 Solution</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Install and import</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install smdebug torch torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import Rule, DebuggerHookConfig, TensorBoardOutputConfig, CollectionConfig, ProfilerRule, rule_configs, ProfilerConfig, FrameworkProfile\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get the data and copy it to S3</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!unzip dogImages.zip\n",
    "!aws s3 cp dogImages s3://udacityproject4-123456/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Set up parameters, estimator, and tuner</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch_size\": CategoricalParameter([32, 64, 128, 256, 512]),\n",
    "}\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "objective_metric_name = \"Test Loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"Test Loss\", \"Regex\": \"Testing Loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    base_job_name='pytorch_dog_hpo',\n",
    "    role=role,\n",
    "    framework_version=\"1.4.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    py_version='py3'\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,  # you once have one ml.g4dn.xlarge instance available\n",
    "    objective_type=objective_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fit the tuner</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............._s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job ended with status 'Stopped' rather than 'Completed'. This could mean the job timed out or stopped early for some other reason: Consider checking whether it completed as you expect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ['SM_CHANNEL_TRAINING']='s3://udacityproject4-123456/'\n",
    "os.environ['SM_MODEL_DIR']='s3://udacityproject4-123456/model/'\n",
    "os.environ['SM_OUTPUT_DATA_DIR']='s3://udacityproject4-123456/output/'\n",
    "tuner.fit({\"training\": \"s3://udacityproject4-123456/\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Describe the tuning results</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"256\"</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>pytorch-training-240912-0755-002-9166700a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>726.0</td>\n",
       "      <td>2024-09-12 08:20:26+00:00</td>\n",
       "      <td>2024-09-12 08:39:49+00:00</td>\n",
       "      <td>1163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"64\"</td>\n",
       "      <td>0.047914</td>\n",
       "      <td>pytorch-training-240912-0755-001-7a2072bf</td>\n",
       "      <td>Completed</td>\n",
       "      <td>290.0</td>\n",
       "      <td>2024-09-12 07:56:13+00:00</td>\n",
       "      <td>2024-09-12 08:16:32+00:00</td>\n",
       "      <td>1219.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  batch_size  learning_rate                            TrainingJobName  \\\n",
       "0      \"256\"       0.013478  pytorch-training-240912-0755-002-9166700a   \n",
       "1       \"64\"       0.047914  pytorch-training-240912-0755-001-7a2072bf   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "0         Completed                726.0 2024-09-12 08:20:26+00:00   \n",
       "1         Completed                290.0 2024-09-12 07:56:13+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0 2024-09-12 08:39:49+00:00                      1163.0  \n",
       "1 2024-09-12 08:16:32+00:00                      1219.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = HyperparameterTuningJobAnalytics(\n",
    "  hyperparameter_tuning_job_name='pytorch-training-240912-0755')\n",
    "\n",
    "jobs = exp.dataframe()\n",
    "\n",
    "jobs.sort_values('FinalObjectiveValue', ascending=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imp: If kernel dies, how to continue from a completed training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-12 08:39:51 Starting - Found matching resource for reuse\n",
      "2024-09-12 08:39:51 Downloading - Downloading the training image\n",
      "2024-09-12 08:39:51 Training - Training image download completed. Training in progress.\n",
      "2024-09-12 08:39:51 Uploading - Uploading generated training model\n",
      "2024-09-12 08:39:51 Completed - Resource released due to keep alive period expiry\n"
     ]
    }
   ],
   "source": [
    "BetterTrainingJobName='pytorch-training-240912-0755-002-9166700a'\n",
    "my_estimator = sagemaker.estimator.Estimator.attach(BetterTrainingJobName)\n",
    "my_estimator.hyperparameters()\n",
    "best_estimator=my_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare to perform Training on Best Estimator</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Best training job not available for tuning job: pytorch-training-240916-0613",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/tuner.py:1455\u001b[0m, in \u001b[0;36mHyperparameterTuner._get_best_training_job\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtuning_job_describe_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBestTrainingJob\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BestTrainingJob'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_estimator\u001b[38;5;241m=\u001b[39m\u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/tuner.py:1419\u001b[0m, in \u001b[0;36mHyperparameterTuner.best_estimator\u001b[0;34m(self, best_training_job)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the estimator that has best training job attached.\u001b[39;00m\n\u001b[1;32m   1394\u001b[0m \n\u001b[1;32m   1395\u001b[0m \u001b[38;5;124;03mThe trained model can then be deployed to an Amazon SageMaker endpoint and return a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;124;03m    Exception: If there is no best training job available for the hyperparameter tuning job.\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_training_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1419\u001b[0m     best_training_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_training_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1422\u001b[0m     best_estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/tuner.py:1457\u001b[0m, in \u001b[0;36mHyperparameterTuner._get_best_training_job\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tuning_job_describe_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBestTrainingJob\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m   1458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest training job not available for tuning job: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1459\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_tuning_job\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   1460\u001b[0m         )\n\u001b[1;32m   1461\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: Best training job not available for tuning job: pytorch-training-240916-0613"
     ]
    }
   ],
   "source": [
    "best_estimator=tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': 'Test Loss',\n",
       " 'batch_size': '\"256\"',\n",
       " 'learning_rate': '0.013478076868080181',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"pytorch_dog_hpo-2024-09-12-07-55-27-690\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-421417664513/pytorch_dog_hpo-2024-09-12-07-55-27-690/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 256, 'learning_rate': '0.013478076868080181'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\"batch_size\": int(best_estimator.hyperparameters()['batch_size'].replace('\"', '')), \\\n",
    "                   \"learning_rate\": best_estimator.hyperparameters()['learning_rate']}\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework profiling will be deprecated from tensorflow 2.12 and pytorch 2.0 in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\n",
    "        \"train.save_interval\": \"1\",\n",
    "        \"eval.save_interval\": \"1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating an Estimator</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"#adjust this cell to accomplish multi-instance training\n",
    "estimator = PyTorch(\n",
    "    entry_point='hpo.py',\n",
    "    base_job_name='dog-pytorch',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    framework_version='1.4.0',\n",
    "    py_version='py3',\n",
    "    hyperparameters=hyperparameters,\n",
    "    ## Debugger and Profiler parameters\n",
    "    rules = rules,\n",
    "    debugger_hook_config=hook_config,\n",
    "    profiler_config=profiler_config,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit({\"training\": \"s3://udacityproject4-123456/\"}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating an Estimator - Multi-Instance Training,</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###in this cell, create and fit an estimator using multi-instance training\n",
    "#adjust this cell to accomplish multi-instance training\n",
    "estimator = PyTorch(\n",
    "    entry_point='hpo.py',\n",
    "    base_job_name='dog-pytorch',\n",
    "    role=role,\n",
    "    instance_count=2,  # Change this to 2 or more for multi-instance training\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    framework_version='1.4.0',\n",
    "    py_version='py3',\n",
    "    hyperparameters=hyperparameters,\n",
    "    ## Debugger and Profiler parameters\n",
    "    rules=rules,\n",
    "    debugger_hook_config=hook_config,\n",
    "    profiler_config=profiler_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: dog-pytorch-2024-09-16-06-17-17-511\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": \"s3://udacityproject4-123456/\"}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deployment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_location=estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import Rule, DebuggerHookConfig, TensorBoardOutputConfig, CollectionConfig, ProfilerRule, rule_configs\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jpeg_serializer = sagemaker.serializers.IdentitySerializer(\"image/jpeg\")\n",
    "json_deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "\n",
    "class ImagePredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(ImagePredictor, self).__init__(\n",
    "            endpoint_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            serializer=jpeg_serializer,\n",
    "            deserializer=json_deserializer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_model = PyTorchModel(model_data=model_location, role=role, entry_point='infernce2.py',py_version='py3',\n",
    "                             framework_version='1.4',\n",
    "                             predictor_cls=ImagePredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-421417664513/dog-pytorch-2024-09-16-06-17-17-511/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-421417664513/pytorch-inference-2024-09-16-06-42-33-838/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-09-16-06-42-43-931\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-inference-2024-09-16-06-42-44-734\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-inference-2024-09-16-06-42-44-734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_model.deploy(initial_instance_count=1, instance_type='ml.m5.large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#request_dict={ \"url\": \"https://cdn1-www.cattime.com/assets/uploads/2011/12/file_2744_british-shorthair-460x290-460x290.jpg\" }\n",
    "request_dict={ \"url\": \"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/20113314/Carolina-Dog-standing-outdoors.jpg\" }\n",
    "\n",
    "img_bytes = requests.get(request_dict['url']).content\n",
    "type(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "Image.open(io.BytesIO(img_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=predictor.predict(img_bytes, initial_args={\"ContentType\": \"image/jpeg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "response2=predictor.predict(json.dumps(request_dict), initial_args={\"ContentType\": \"application/json\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "np.argmax(response, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
